This is code to import the pooled distance data from Yencken and Baldwin (2008). (https://lars.yencken.org/papers/coling-2008.pdf)

The original files can be downloaded from https://lars.yencken.org/datasets/kanji-confusion.

```{r}
library(R.utils)
library(yaml)
library(tidyverse)
library(kanjistat)

file_path <- "poolexp_judgements.yaml.gz"

load_yaml <- function (fp) {
  connection <- gzfile(fp, "r")
  yaml_text <- readLines(connection, warn = FALSE) 
  close(connection) 
  
  
  yaml_data_list <- list() 
  current_doc <- ""
  
  for (line in yaml_text) {
    if (startsWith(line, "---")) {
      if (current_doc != "") {
        yaml_data_list[[length(yaml_data_list) + 1]] <- yaml.load(current_doc)
      }
      current_doc <- ""
    } else {
      current_doc <- paste0(current_doc, line, "\n")
    }
  }
  
  
  if (current_doc != "") {
     yaml_data_list[[length(yaml_data_list) + 1]] <- yaml.load(current_doc)
  }
  
  yaml_data_list
}

yaml_data_list <- load_yaml(file_path)

process_doc <- function(doc) {
  tibble(
    pivot = doc$pivot,
    selected = paste(doc$selected, collapse = ", "),
    distractors = paste(doc$distractors, collapse = ", ")
  )
}


pooled_similarity <- lapply(yaml_data_list, process_doc) %>% bind_rows()


save(pooled_similarity, file="../data/dpooledsimilarity.rda", compress="xz")   
```


```{r}
kanjiToKvec <- function(kan) {
  # Assuming a kanjivec object as returned by kanjistat::kanjivec loaded as kvec, get a kanjivec object from the string.
  # In case the index is out of bounds, we return the first kanji and alert.
  results <- lapply(kan, function(x) {
    index <- match(x, kbase$kanji)
    if (index > length(kvec) || index < 1) {
      index <- 1
      print(c(x, " was out of bounds for kvec database."))
    }
    kvec[[index]] 
  })
}

jaccard_index <- function(array1, array2) {
  # Convert arrays to sets
  set1 <- unique(array1)
  set2 <- unique(array2)
  
  intersection <- length(intersect(set1, set2))
  union <- length(union(set1, set2))
  
  return(intersection / union)
}

pooled_distance_benchmark <- function(distance, sample_size) {
  # Tests the provided distance function on the Yencken and Baldwin (2008)
  # Pooled distance Experiment Data. For each distractor the distance to the
  # pivot character is computed. The rank to the given distance of the most 
  # similar kanji according to the human evaluators (can be more than one) is
  # then compared.
  # The input function should be curried with anonymous functions in such a way
  # that it accepts two single kanji and nothing else as outputs.
  # The benchmark will do around 5*sample_size comparisons.
  
  file_path <- "../data/dpooledsimilarity.rda"
  load(file_path)  # Load the RData file
  
  df <- pooled_similarity
  df <- pooled_similarity[sample(nrow(df), sample_size), ]
  df$distractors <- lapply(1:nrow(df), function(i) {strsplit(df$distractors[i], ", ")[[1]]})
  
  # Calculate distance and rank (assuming 'df' is the loaded dataframe)
  df$distances <- lapply(1:nrow(df), function(i) {
  unlist(lapply(kanjiToKvec(df$distractors[[i]]), function(x) {
     distance(k1=x, k2=kanjiToKvec(df$pivot[i])[[1]])  
   }))
})
  
  df$distance_rank <- lapply(1:nrow(df), function(i) {rank(df$distances[[i]], ties.method = "max")})
  df$selected_indices <- lapply(1:nrow(df), function(i) {which(df$distractors[[i]] %in% strsplit(df$selected[i], ", ")[[1]])})
  
  df$first_selected_rank <- NA  # Create a column to store results

  for (i in 1:nrow(df)) {
    if (length(df$selected_indices[[i]]) > 0) {  # Check if selected_indices is not empty
      first_index <- df$selected_indices[[i]][1]  # Get the first element
      df$first_selected_rank[i] <- df$distance_rank[[i]][first_index] 
    } 
  }
  
  df$jaccard <- lapply(1:nrow(df), function (i) {jaccard_index(order(df$distances[[i]])[1:length(df$selected_indices[[i]])], df$selected_indices[[i]])})

  
  df
}
results <- pooled_distance_benchmark(kanjidist, 100)

df <- results

hist(unlist(df$jaccard))
```

Next, we load data from [Yencken and Baldwin (2006)](https://lars.yencken.org/papers/iccpol-2006.pdf).

```{r}
# Using the loading function from above to process participant data.
participants <- load_yaml("kanjiexp_participants.yaml.gz")

process_doc <- function(doc) {
  tibble(
    id = doc$id,
    ability = doc$ability,
    comment = doc$comment,
    firstLanguage = doc$firstLanguage,
    numResponses = doc$numResponses,
    numKanji = doc$numKanji,
    kanjiSetId = doc$kanjiSetId,
    languageGroup = doc$languageGroup,
    startTime = parse_datetime(doc$startTime),
    finishTime = parse_datetime(doc$finishTime),
    stimulusSet = doc$stimulusSet
    
  )
}

participants <- lapply(participants, process_doc) %>% bind_rows()

# We now select a subset of participant ids, in this case Japanese learners 
# whose first languages does not use Hanzi/Kanji/Hanja. This is done with
# the language group field, which is also used in the original study. 
JSL_IDs <- filter(participants, participants["languageGroup"] == "JSL")[["id"]]
```
```{r}
judgements <- load_yaml("kanjiexp_judgements.yaml.gz")

process_doc <- function(doc) {
  tibble(
    k1 = doc$kanjiA,
    k2 = doc$kanjiB,
    id = doc$participantId,
    value = doc$value
  )
}

judgements <- lapply(judgements, process_doc) %>% bind_rows()

# We invert the similarity judgement on a scale from 0-4 to a distance judgment 0-1
judgements$value <- 1 - judgements$value / 4

filtered <- filter(judgements, judgements[["id"]] %in% JSL_IDs)
```

We add a computed similarity as a column and compute Spearman's rho.

```{r}
# This takes in two chars, as an example a (not so useful) function returning the stroke edit distance if available
stroke_edit_distance <- function(k1,k2) {
  k1 <- match(k1, kbase$kanji)
  k2 <- match(k2, kbase$kanji)
  
  if (k1 < nrow(dstrokedit) && k2 < nrow(dstrokedit)) {
    if (dstrokedit[k1, k2] == 0) {
      NA
    } else {
      dstrokedit[k1, k2]
    }
  } else {
    NA
  }
} 

# We use our kanji distance, assuming kvec is loaded.
# 
kanjistat_distance <- function(k1,k2) {
  k1 <- match(k1, kbase$kanji)
  k2 <- match(k2, kbase$kanji)
  
  if (k1 > length(kvec) || k2 > length(kvec)) {
    return(NA)
  }

  k1 <- kvec[[k1]]
  k2 <- kvec[[k2]]
  
  kanjidist(k1, k2, approx="pcweighted")
}

```
We have to sample for now because kanjidist is computationally expensive.

```{r}
sampled <- filtered[sample(nrow(filtered), size=100), ]

# We compute our distance for the pairs
sampled$kanjistat <- lapply(1:nrow(sampled), function(i) {kanjistat_distance(sampled$k1[[i]], sampled$k2[[i]])})
sampled$kanjistat <- as.numeric(sampled$kanjistat)

# This dataset contains many non-joyo kanji, so we 
# TODO: We should use kvec for non-joyo kanji instead of filtering them out, probably.
sampled <- sampled[!is.na(sampled$kanjistat), ]

# Lastly we compute the rank correlation
rho <- cor(sampled$kanjistat, sampled$value, method = "spearman")

print(rho)
```




